# Tutorial

```elixir
Mix.install([
  {:openai_responses, path: "~/src/openai_responses"}
])
```

## Introduction

The only setup you need for using the library is to get your OpenAI API token. If you already have the `OPENAI_API_KEY` environment variable set, then you can start right away.

```elixir
alias OpenAI.Responses
alias OpenAI.Responses.Helpers
alias OpenAI.Responses.Stream
```

<!-- livebook:{"branch_parent_index":0} -->

## Basic usage

`create/2` requires just two arguments: the name of the model, and the input text:

```elixir
{:ok, response} = Responses.create("gpt-4o", "Write a haiku about programming")
```

The `response` is just a map, and you can use helper functions to extract information from it:

```elixir
Helpers.has_refusal?(response)
```

```elixir
Helpers.output_text(response)
```

```elixir
Helpers.token_usage(response)
```

A *structured* input can be manually constructed and passed to `create/2`:

```elixir
input = [
  %{
    "role" => "user",
    "content" => [
      %{"type" => "input_text", "text" => "What is in this image?"},
      %{
        "type" => "input_image",
        "image_url" => "https://upload.wikimedia.org/wikipedia/commons/d/d2/Three_early_medicine_bottles.jpg"
      }
    ]
  }
]

{:ok, response} = OpenAI.Responses.create("gpt-4o", input)
IO.puts Helpers.output_text(response)
```

<!-- livebook:{"branch_parent_index":0} -->

## Image helpers

As we saw in the previous section, you can manually create a structured input with images, but this requires writing verbose JSON-like structures. The library provides helper functions to make this process more ergonomic.

```elixir
# Using the helper function to create a message with an image
input_message = Helpers.create_message_with_images(
  "What is in this image?", 
  "https://upload.wikimedia.org/wikipedia/commons/d/d2/Three_early_medicine_bottles.jpg"
)

# The helper creates the same structure as the manual approach, but with less code
input_message
```

You can also specify multiple images with different detail levels:

```elixir
multi_image_message = Helpers.create_message_with_images(
  "Compare these two images",
  [
    {"https://upload.wikimedia.org/wikipedia/commons/d/d2/Three_early_medicine_bottles.jpg", "high"},
    "https://upload.wikimedia.org/wikipedia/commons/4/48/Cocacolacollection.JPG"
  ],
  detail: "low"  # Default detail level for images without a specific level
)

# And then use it with the API
{:ok, response} = OpenAI.Responses.create("gpt-4o", [multi_image_message])
IO.puts Helpers.output_text(response)
```

Local image files are also supported and will be automatically encoded as base64 data URLs:

```elixir
# This would work if you have these image files locally
# local_image_message = Helpers.create_message_with_images(
#   "Describe these local images",
#   ["path/to/image1.jpg", "path/to/image2.png"]
# )
```

The helper function eliminates boilerplate code, handles encoding of local images, and provides a more intuitive interface for working with images in your prompts.

<!-- livebook:{"branch_parent_index":0} -->

## Using built-in tools

The usage of built-in tools can be illustrated by the following example:

```elixir
{:ok, response_no_tools} = Responses.create("gpt-4o", "What's the weather in San Francisco?")
IO.puts(Helpers.output_text(response_no_tools))
```

```elixir
{:ok, response_with_search} =
  Responses.create("gpt-4o", "What's the weather in San Francisco?",
    tools: [%{type: "web_search_preview"}],
    temperature: 0.7
  )

IO.puts(Helpers.output_text(response_with_search))
```

<!-- livebook:{"branch_parent_index":0} -->

## Streaming responses

OpenAI.Responses supports true streaming, where you can process chunks as they arrive without waiting for the entire response to complete.

### Real-time text streaming

This example demonstrates how to display text as it arrives, for a "typing" effect:

```elixir
# Create a stream from OpenAI
stream = Responses.create_stream("gpt-4o", "Write a short poem about coding")

# Initialize the stream handler
stream_handler = Stream.new(stream)

# Extract text chunks that can be processed in real-time
text_chunks = Stream.text_chunks(stream_handler)

# Process each chunk as it arrives
# In Livebook, accumulate text to see the result
result = Enum.reduce(text_chunks, "", fn chunk, acc ->
  # In a real application, you would use IO.write for true streaming
  # IO.write(chunk)
  # Process.sleep(10)  # Optional: For a typing effect
  
  # For Livebook, accumulate the chunks
  acc <> chunk
end)

# Display the final result in Livebook
result
```

### Processing raw events

If you need to handle all event types from the stream:

```elixir
alias OpenAI.Responses
alias OpenAI.Responses.Stream

# Create a stream
stream = Responses.create_stream("gpt-4o", "Write me a story")

# Define a custom event handler function
event_processor = fn event ->
  case event do
    %{"type" => "response.output_text.delta", "delta" => delta} ->
      # Process text deltas (chunks) in real-time
      IO.write(delta)
      event
    %{"type" => "response.output_text.done", "text" => text} ->
      # Handle completed text output
      IO.puts("\nCompleted text: #{String.slice(text, 0..10)}...")
      event
    %{"type" => "response.completed"} ->
      # Handle stream completion
      IO.puts("\nStream completed!")
      event
    _ ->
      # Handle other event types
      event
  end
end

# Apply the processor to the stream 
# Note that we need to fully qualify the module to avoid confusion with Elixir's Stream
stream_handler = OpenAI.Responses.Stream.new(stream)
processed_stream = OpenAI.Responses.Stream.transform(stream_handler, event_processor)

# Collect just a few events to demo (in a real app, you'd process the full stream)
Enum.take(processed_stream, 10)
```

### Building a complete response

If you need the final assembled response after streaming:

```elixir
# Create a stream
stream = Responses.create_stream("gpt-4o", "What's 5+7?")

# Initialize the stream handler
stream_handler = Stream.new(stream)

# Collect a complete response from the stream
# This processes all events and assembles them into a final response object
complete_response = Stream.collect(stream_handler)

# Extract text from the collected response
Helpers.output_text(complete_response)
```
